# Behind_The_Gesture

Sign language is a way by which deaf and dumb people can express their thoughts and feelings. Deaf and dumb people use hand shape, body movements, and facial expressions for communication. In this work, a vision-based Indian Sign Language Recognition system using a convolutional neural network (CNN) is implemented. The sign images are captured by a web camera.
To segment the hand region, background subtraction method is used.
Two datasets have been created for ISL. Each of the datasets contains 26 alphabets having a total of 6,500 images.
And it has been named as test_set and training_set.
The system has also been tested in real time, where the sign alphabets by me and my friend in front of the camera are captured and it correctly recognizes almost all of the signs.
Accuracy of around 99.40% is obtained.
